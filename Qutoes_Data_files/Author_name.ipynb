{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement\n",
    "Find and print the names of all the different authors from all pages of this website\n",
    "\n",
    "Note : Print the names of all authors line wise sorted in dictionary order\n",
    "\n",
    "#### Output Format :\n",
    "author1\n",
    "author2\n",
    "author3\n",
    ".\n",
    ".\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "J.K. Rowling\n",
      "Albert Einstein\n",
      "Jane Austen\n",
      "Marilyn Monroe\n",
      "Albert Einstein\n",
      "André Gide\n",
      "Thomas A. Edison\n",
      "Eleanor Roosevelt\n",
      "Steve Martin\n"
     ]
    }
   ],
   "source": [
    "URL = 'http://quotes.toscrape.com/'\n",
    "\n",
    "response = requests.get(URL)\n",
    "response_data=BeautifulSoup(response.text)\n",
    "# print(response_data)\n",
    "for container_Data in response_data.find_all('div',{'class':'col-md-8'}):\n",
    "  # print(container_Data)\n",
    "  for div_data in container_Data.find_all('div',{'class':'quote'}):\n",
    "    # print(div_data.text)\n",
    "    # for author in div_data.find_all('span',{'class':'author'}):\n",
    "      for author_name in div_data.find_all('small',{'class':'author'}):\n",
    "         print(author_name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "André Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests  # Used to send HTTP requests to the specified URL\n",
    "import time  # Library for working with time (although it's not being used here)\n",
    "from bs4 import BeautifulSoup  # Library for parsing HTML content from a webpage\n",
    "\n",
    "# Initialize a set to store unique authors\n",
    "authors = set()\n",
    "\n",
    "# Loop through the first 10 pages of the website\n",
    "for i in range(1, 11):  # Loop from page 1 to page 10\n",
    "    page = requests.get(\"http://quotes.toscrape.com/page/\" + str(i) + \"/\")  # Send a GET request to the URL for the specific page\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')  # Parse the HTML content of the page using BeautifulSoup\n",
    "    \n",
    "    # Loop through all the elements with the class 'author' (each author name)\n",
    "    for aut in soup.select(\".author\"):  # Use CSS selectors to find all elements with class 'author'\n",
    "        authors.add(aut.text)  # Add the author's name (text) to the 'authors' set, which avoids duplicates\n",
    "\n",
    "# Loop through the sorted list of authors\n",
    "for i in sorted(authors):  # Sort the authors alphabetically before printing\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
